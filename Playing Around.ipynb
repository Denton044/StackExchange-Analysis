{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from src.preprocessing import cleanhtml_test\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: SparkContext already exists in this scope\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # we try to create a SparkContext to work locally on all cpus available\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    print(\"Just created a SparkContext\")\n",
    "except ValueError:\n",
    "    # give a warning if SparkContext already exists (for use inside pyspark)\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.3.32.141:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[4] appName=PySparkShell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data into two tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infile = 'csvs/posts.csv'\n",
    "# outfile = 'csvs/dev_set.csv'\n",
    "# models.create_dev_set(infile, outfile)\n",
    "df = pd.read_csv('csvs/dev_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = spark.read.csv('csvs/dev_set.csv', \n",
    "                          header=True, \n",
    "                          encoding = 'utf8',\n",
    "                          quote ='\"',\n",
    "                          escape=None,\n",
    "                          multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "|_c0|post_Id|               title|                body|score|   views|comments|\n",
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "|  0|      4|While applying op...|<p>I want to use ...|  543| 34799.0|       1|\n",
      "|  1|      6|Percentage width ...|<p>I have an abso...|  241| 15696.0|       0|\n",
      "|  2|      7|                null|<p>An explicit ca...|  391|    null|       0|\n",
      "|  3|      9|How do I calculat...|<p>Given a <code>...| 1716|439828.0|      16|\n",
      "|  4|     11|Calculate relativ...|<p>Given a specif...| 1286|130055.0|       3|\n",
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('csvs/posts.csv',\n",
    "                         header=True,       # use headers or not\n",
    "                         inferSchema=True)  # do we infer schema or not ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = spark.read.csv('csvs/tags_posts_rel.csv',\n",
    "                         header=True,       # use headers or not\n",
    "                         quote='\"',         # char for quotes\n",
    "                         sep=\",\",           # char for separation\n",
    "                         inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----+------+--------+\n",
      "|post_Id|               title|                body|score| views|comments|\n",
      "+-------+--------------------+--------------------+-----+------+--------+\n",
      "|      4|While applying op...|<p>I want to use ...|  543| 34799|       1|\n",
      "|      6|Percentage width ...|<p>I have an abso...|  241| 15696|       0|\n",
      "|      7|                null|<p>An explicit ca...|  391|  null|       0|\n",
      "|      9|How do I calculat...|<p>Given a <code>...| 1716|439828|      16|\n",
      "|     11|Calculate relativ...|<p>Given a specif...| 1286|130055|       3|\n",
      "|     12|                null|<p>Here's how I d...|  313|  null|      10|\n",
      "|     13|Determine a User'...|<p>Is there any s...|  519|149911|       6|\n",
      "|     14|Difference betwee...|<p>What is the di...|  352|102761|       3|\n",
      "|     16|Filling a DataSet...|<p>How do you exp...|  106| 77797|       0|\n",
      "|     17|Binary Data in MySQL|<p>How do I store...|  159| 61581|       3|\n",
      "+-------+--------------------+--------------------+-----+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|post_Id|  tag_id|\n",
      "+-------+--------+\n",
      "|      4|      c#|\n",
      "|      4|winforms|\n",
      "+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39646923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_Id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- comments: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_Id: integer (nullable = true)\n",
      " |-- tag_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to first take a look at the tags and see how many we are working with here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags.registerTempTable('post_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51672"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT DISTINCT tag_id\n",
    "            FROM post_tags\n",
    "            \"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets select only tags that have over 50k posts, that should give us plenty to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_with_100k = spark.sql(\"\"\"\n",
    "                    SELECT tag_id, Count(post_Id)\n",
    "                    FROM post_tags\n",
    "                    GROUP BY tag_id\n",
    "                    HAVING COUNT(post_Id) > 200000\n",
    "                    \"\"\")\n",
    "tags_with_100k.registerTempTable('top_tags')\n",
    "tags_with_100k.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|       tag_id|count(post_Id)|\n",
      "+-------------+--------------+\n",
      "|       iphone|        218782|\n",
      "|      android|       1081802|\n",
      "|      node.js|        216420|\n",
      "|           c#|       1188414|\n",
      "|         html|        733142|\n",
      "|      asp.net|        330632|\n",
      "|         json|        228383|\n",
      "|        mysql|        509242|\n",
      "|       jquery|        900794|\n",
      "|   javascript|       1576130|\n",
      "|          css|        524689|\n",
      "|       arrays|        257543|\n",
      "|          sql|        430275|\n",
      "|   sql-server|        226832|\n",
      "|          c++|        559729|\n",
      "|            c|        272952|\n",
      "|  objective-c|        282994|\n",
      "|         java|       1385397|\n",
      "|            r|        227621|\n",
      "|          php|       1176839|\n",
      "|         .net|        265331|\n",
      "|          ios|        554171|\n",
      "|       python|        914075|\n",
      "|    angularjs|        250039|\n",
      "|ruby-on-rails|        288879|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_with_100k.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all those tags lets fish out relevant ids and posts we will be working with this will become our data to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Lets fish out posts with tags with over 100k\n",
    "inner_join = spark.sql(\"\"\"\n",
    "                    SELECT DISTINCT post_tags.post_Id as post_id\n",
    "                    FROM post_tags\n",
    "                    INNER JOIN top_tags\n",
    "                    ON post_tags.tag_id = top_tags.tag_id\n",
    "                    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|post_id|\n",
      "+-------+\n",
      "| 351954|\n",
      "| 491584|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inner_join.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|post_Id|                text|\n",
      "+-------+--------------------+\n",
      "|    833|Editing database ...|\n",
      "|   1829|How do I make a m...|\n",
      "|   6658|JUnit vs TestNG <...|\n",
      "|   7880|How do you open a...|\n",
      "|   9376|ILMerge Best Prac...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('all_posts')\n",
    "inner_join.registerTempTable('relevant_ids')\n",
    "relevant_posts = spark.sql(\"\"\"\n",
    "                            SELECT all_posts.post_Id, CONCAT(all_posts.title, ' ', all_posts.body) as text\n",
    "                            FROM all_posts\n",
    "                            INNER JOIN relevant_ids\n",
    "                            ON all_posts.post_Id = relevant_ids.post_id\n",
    "                            \"\"\")\n",
    "relevant_posts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10773100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_posts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets clean the body of the text, code vs text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "|_c0|post_Id|               title|                body|score|   views|comments|\n",
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "|  0|      4|While applying op...|<p>I want to use ...|  543| 34799.0|       1|\n",
      "|  1|      6|Percentage width ...|<p>I have an abso...|  241| 15696.0|       0|\n",
      "|  2|      7|                null|<p>An explicit ca...|  391|    null|       0|\n",
      "|  3|      9|How do I calculat...|<p>Given a <code>...| 1716|439828.0|      16|\n",
      "|  4|     11|Calculate relativ...|<p>Given a specif...| 1286|130055.0|       3|\n",
      "|  5|     12|                null|<p>Here's how I d...|  313|    null|      10|\n",
      "|  6|     13|Determine a User'...|<p>Is there any s...|  519|149911.0|       6|\n",
      "|  7|     14|Difference betwee...|<p>What is the di...|  352|102761.0|       3|\n",
      "|  8|     16|Filling a DataSet...|<p>How do you exp...|  106| 77797.0|       0|\n",
      "|  9|     17|Binary Data in MySQL|<p>How do I store...|  159| 61581.0|       3|\n",
      "| 10|     18|                null|<p>For a table li...|   50|    null|       2|\n",
      "| 11|     19|What is the faste...|<p>Solutions are ...|  265| 40266.0|      14|\n",
      "| 12|     21|                null|<p>Many years ago...|   31|    null|       1|\n",
      "| 13|     22|                null|<p>The best way t...|   24|    null|       0|\n",
      "| 14|     24|Throw an error in...|<p>If I have a <c...|  132| 56924.0|       0|\n",
      "| 15|     25|How to use the C ...|<p>I've been havi...|  124|  8562.0|       0|\n",
      "| 16|     26|                null|<p>The answer by ...|  122|    null|       0|\n",
      "| 17|     27|                null|<p>@jeff</p><p>IM...|   28|    null|       0|\n",
      "| 18|     29|                null|<p>There are no H...|   73|    null|       4|\n",
      "| 19|     30|                null|<p>I've had no tr...|   32|    null|       0|\n",
      "+---+-------+--------------------+--------------------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaner_udf = F.udf(cleanhtml_test, StringType())\n",
    "cleaned_data = relevant_posts.withColumn(\"cleaned\", cleaner_udf(relevant_posts.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dev_set, hold_set = relevant_posts.randomSplit([0.7,0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hold_set.write.csv('holdset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|post_Id|                text|\n",
      "+-------+--------------------+\n",
      "|    833|Editing database ...|\n",
      "|   1829|How do I make a m...|\n",
      "+-------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.registerTempTable(\"clean_data\")\n",
    "clean_stuff = spark.sql(\"\"\"\n",
    "                            SELECT post_Id, text\n",
    "                            FROM clean_data\n",
    "                            \"\"\")\n",
    "clean_stuff.show(2)\n",
    "dev_set, hold_set = clean_stuff.randomSplit([0.7,0.3])\n",
    "\n",
    "# cleaned_data.write.csv('csvs/cleaned_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dev_set.write.csv('clean_dev_set')\n",
    "# hold_set.write.csv('clean_holdout_set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dev_set.registerTempTable(\"dev_set\")\n",
    "# dev_set = spark.sql(\"\"\"\n",
    "#                             SELECT post_Id, title, cleaned\n",
    "#                             FROM dev_set\n",
    "#                             \"\"\")\n",
    "# # dev_set.write.csv('dev_set.csv')\n",
    "# dev_set.show(2)\n",
    "# # cleaned_body = cleaned_data.select(\"cleaned\")\n",
    "# # cleaned_body.write.csv('body_text_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
